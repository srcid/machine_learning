{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age    sex    cp     trestbps  chol   fbs    restecg  thalach  exang  oldpeak  slope  ca     thal   target\n",
       "False  False  False  False     False  False  False    False    False  False    False  False  False  False     1025\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex           int64\n",
       "cp            int64\n",
       "trestbps      int64\n",
       "chol          int64\n",
       "fbs           int64\n",
       "restecg       int64\n",
       "thalach       int64\n",
       "exang         int64\n",
       "oldpeak     float64\n",
       "slope         int64\n",
       "ca            int64\n",
       "thal          int64\n",
       "target        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0      52    1   0       125   212    0        1      168      0      1.0   \n",
       "1      53    1   0       140   203    1        0      155      1      3.1   \n",
       "2      70    1   0       145   174    0        1      125      1      2.6   \n",
       "3      61    1   0       148   203    0        1      161      0      0.0   \n",
       "4      62    0   0       138   294    1        1      106      0      1.9   \n",
       "...   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "1020   59    1   1       140   221    0        1      164      1      0.0   \n",
       "1021   60    1   0       125   258    0        0      141      1      2.8   \n",
       "1022   47    1   0       110   275    0        0      118      1      1.0   \n",
       "1023   50    0   0       110   254    0        0      159      0      0.0   \n",
       "1024   54    1   0       120   188    0        1      113      0      1.4   \n",
       "\n",
       "      slope  ca  thal  target  \n",
       "0         2   2     3       0  \n",
       "1         0   0     3       0  \n",
       "2         0   0     3       0  \n",
       "3         2   1     3       0  \n",
       "4         1   3     2       0  \n",
       "...     ...  ..   ...     ...  \n",
       "1020      2   0     2       1  \n",
       "1021      1   1     3       0  \n",
       "1022      1   1     2       0  \n",
       "1023      2   0     2       1  \n",
       "1024      1   1     3       0  \n",
       "\n",
       "[1025 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparar o RMSE das seguintes implementaÃ§Ãµes do Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "  'lr': LinearRegression(),\n",
    "  'sgd': SGDRegressor(),\n",
    "  'ridge': Ridge(),\n",
    "  'lasso': Lasso(),\n",
    "  'enet': ElasticNet()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "  ('pre', ColumnTransformer([\n",
    "    ('std', StandardScaler(), [x for x in range(13)])\n",
    "  ])),\n",
    "  ('est', None)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "  {\n",
    "    \"est__fit_intercept\": [True, False],\n",
    "    \"est__copy_X\": [True, False],\n",
    "    \"est__positive\": [True, False],\n",
    "    \"est\": [models['lr']]\n",
    "  },\n",
    "  {\n",
    "    \"est__penalty\": ['l1', 'l2', 'elasticnet'],\n",
    "    \"est__alpha\": [1e-3, 1e-4, 1e-5], \n",
    "    \"est__max_iter\": [1500, 1000, 500],\n",
    "    \"est__early_stopping\": [True, False],\n",
    "    \"est__random_state\": [42],\n",
    "    \"est\": [models['sgd']]\n",
    "  },\n",
    "  {\n",
    "    \"est__alpha\": [0.5, 1.0, 1.5],\n",
    "    \"est__max_iter\": [None, 1000, 5000],\n",
    "    \"est__random_state\": [42],\n",
    "    \"est\": [models['ridge']]\n",
    "  },\n",
    "  {\n",
    "    \"est__alpha\": [0.5, 1.0, 1.5],\n",
    "    \"est__max_iter\": [500, 1000, 1500],\n",
    "    \"est__random_state\": [42],\n",
    "    \"est\": [models['lasso']]\n",
    "  },\n",
    "  {\n",
    "    \"est__alpha\": [0.5, 1.0, 1.5], \n",
    "    \"est__l1_ratio\": [0.1, 0.5, 0.9], \n",
    "    \"est__max_iter\": [500, 1000, 1500],\n",
    "    \"est__random_state\": [42],\n",
    "    \"est\": [models['enet']]\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipe, params, cv=3, n_jobs=-1, return_train_score=True, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('pre',\n",
       "                                        ColumnTransformer(transformers=[('std',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         [0, 1,\n",
       "                                                                          2, 3,\n",
       "                                                                          4, 5,\n",
       "                                                                          6, 7,\n",
       "                                                                          8, 9,\n",
       "                                                                          10,\n",
       "                                                                          11,\n",
       "                                                                          12])])),\n",
       "                                       ('est', None)]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'est': [LinearRegression()],\n",
       "                          'est__copy_X': [True, False],\n",
       "                          'est__fit_intercept': [True, False],\n",
       "                          'est__positive': [True, False]},\n",
       "                         {'est': [SGDRegressor(alpha=0.001, early_stopping=True...\n",
       "                          'est__max_iter': [None, 1000, 5000],\n",
       "                          'est__random_state': [42]},\n",
       "                         {'est': [Lasso()], 'est__alpha': [0.5, 1.0, 1.5],\n",
       "                          'est__max_iter': [500, 1000, 1500],\n",
       "                          'est__random_state': [42]},\n",
       "                         {'est': [ElasticNet()], 'est__alpha': [0.5, 1.0, 1.5],\n",
       "                          'est__l1_ratio': [0.1, 0.5, 0.9],\n",
       "                          'est__max_iter': [500, 1000, 1500],\n",
       "                          'est__random_state': [42]}],\n",
       "             return_train_score=True, scoring='neg_root_mean_squared_error')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.35477331148305363\n"
     ]
    }
   ],
   "source": [
    "print( -1 * (mean_squared_error(y_pred=y_pred, y_true=y_test)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_est</th>\n",
       "      <th>param_est__copy_X</th>\n",
       "      <th>param_est__fit_intercept</th>\n",
       "      <th>param_est__positive</th>\n",
       "      <th>param_est__alpha</th>\n",
       "      <th>param_est__early_stopping</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.408159</td>\n",
       "      <td>-0.446001</td>\n",
       "      <td>-0.414480</td>\n",
       "      <td>0.023583</td>\n",
       "      <td>69</td>\n",
       "      <td>-0.420502</td>\n",
       "      <td>-0.409594</td>\n",
       "      <td>-0.391547</td>\n",
       "      <td>-0.407215</td>\n",
       "      <td>0.011940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050557</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.338478</td>\n",
       "      <td>-0.391365</td>\n",
       "      <td>-0.359093</td>\n",
       "      <td>0.023111</td>\n",
       "      <td>64</td>\n",
       "      <td>-0.352692</td>\n",
       "      <td>-0.354747</td>\n",
       "      <td>-0.329169</td>\n",
       "      <td>-0.345536</td>\n",
       "      <td>0.011604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669386</td>\n",
       "      <td>-0.676608</td>\n",
       "      <td>-0.659517</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>106</td>\n",
       "      <td>-0.676007</td>\n",
       "      <td>-0.635802</td>\n",
       "      <td>-0.654674</td>\n",
       "      <td>-0.655494</td>\n",
       "      <td>0.016424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.041822</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.630327</td>\n",
       "      <td>-0.633520</td>\n",
       "      <td>-0.626791</td>\n",
       "      <td>0.007375</td>\n",
       "      <td>104</td>\n",
       "      <td>-0.636046</td>\n",
       "      <td>-0.601932</td>\n",
       "      <td>-0.619388</td>\n",
       "      <td>-0.619122</td>\n",
       "      <td>0.013928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.408159</td>\n",
       "      <td>-0.446001</td>\n",
       "      <td>-0.414480</td>\n",
       "      <td>0.023583</td>\n",
       "      <td>69</td>\n",
       "      <td>-0.420502</td>\n",
       "      <td>-0.409594</td>\n",
       "      <td>-0.391547</td>\n",
       "      <td>-0.407215</td>\n",
       "      <td>0.011940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>ElasticNet()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.502042</td>\n",
       "      <td>-0.501060</td>\n",
       "      <td>-0.501676</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>80</td>\n",
       "      <td>-0.499141</td>\n",
       "      <td>-0.499812</td>\n",
       "      <td>-0.499391</td>\n",
       "      <td>-0.499448</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.002346</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>ElasticNet()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.502042</td>\n",
       "      <td>-0.501060</td>\n",
       "      <td>-0.501676</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>80</td>\n",
       "      <td>-0.499141</td>\n",
       "      <td>-0.499812</td>\n",
       "      <td>-0.499391</td>\n",
       "      <td>-0.499448</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>ElasticNet()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.502042</td>\n",
       "      <td>-0.501060</td>\n",
       "      <td>-0.501676</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>80</td>\n",
       "      <td>-0.499141</td>\n",
       "      <td>-0.499812</td>\n",
       "      <td>-0.499391</td>\n",
       "      <td>-0.499448</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.002122</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>ElasticNet()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.502042</td>\n",
       "      <td>-0.501060</td>\n",
       "      <td>-0.501676</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>80</td>\n",
       "      <td>-0.499141</td>\n",
       "      <td>-0.499812</td>\n",
       "      <td>-0.499391</td>\n",
       "      <td>-0.499448</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>ElasticNet()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.502042</td>\n",
       "      <td>-0.501060</td>\n",
       "      <td>-0.501676</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>80</td>\n",
       "      <td>-0.499141</td>\n",
       "      <td>-0.499812</td>\n",
       "      <td>-0.499391</td>\n",
       "      <td>-0.499448</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.002906      0.000347         0.000976        0.000068   \n",
       "1         0.050557      0.008624         0.000947        0.000007   \n",
       "2         0.002279      0.000241         0.000944        0.000074   \n",
       "3         0.041822      0.002362         0.000849        0.000132   \n",
       "4         0.001672      0.000299         0.000675        0.000170   \n",
       "..             ...           ...              ...             ...   \n",
       "102       0.002304      0.000053         0.000916        0.000002   \n",
       "103       0.002346      0.000088         0.000751        0.000119   \n",
       "104       0.002466      0.000361         0.000943        0.000085   \n",
       "105       0.002122      0.000363         0.000714        0.000074   \n",
       "106       0.001476      0.000022         0.000535        0.000042   \n",
       "\n",
       "              param_est param_est__copy_X param_est__fit_intercept  \\\n",
       "0    LinearRegression()              True                     True   \n",
       "1    LinearRegression()              True                     True   \n",
       "2    LinearRegression()              True                    False   \n",
       "3    LinearRegression()              True                    False   \n",
       "4    LinearRegression()             False                     True   \n",
       "..                  ...               ...                      ...   \n",
       "102        ElasticNet()               NaN                      NaN   \n",
       "103        ElasticNet()               NaN                      NaN   \n",
       "104        ElasticNet()               NaN                      NaN   \n",
       "105        ElasticNet()               NaN                      NaN   \n",
       "106        ElasticNet()               NaN                      NaN   \n",
       "\n",
       "    param_est__positive param_est__alpha param_est__early_stopping  ...  \\\n",
       "0                  True              NaN                       NaN  ...   \n",
       "1                 False              NaN                       NaN  ...   \n",
       "2                  True              NaN                       NaN  ...   \n",
       "3                 False              NaN                       NaN  ...   \n",
       "4                  True              NaN                       NaN  ...   \n",
       "..                  ...              ...                       ...  ...   \n",
       "102                 NaN              1.5                       NaN  ...   \n",
       "103                 NaN              1.5                       NaN  ...   \n",
       "104                 NaN              1.5                       NaN  ...   \n",
       "105                 NaN              1.5                       NaN  ...   \n",
       "106                 NaN              1.5                       NaN  ...   \n",
       "\n",
       "    split1_test_score split2_test_score mean_test_score std_test_score  \\\n",
       "0           -0.408159         -0.446001       -0.414480       0.023583   \n",
       "1           -0.338478         -0.391365       -0.359093       0.023111   \n",
       "2           -0.669386         -0.676608       -0.659517       0.019291   \n",
       "3           -0.630327         -0.633520       -0.626791       0.007375   \n",
       "4           -0.408159         -0.446001       -0.414480       0.023583   \n",
       "..                ...               ...             ...            ...   \n",
       "102         -0.502042         -0.501060       -0.501676       0.000438   \n",
       "103         -0.502042         -0.501060       -0.501676       0.000438   \n",
       "104         -0.502042         -0.501060       -0.501676       0.000438   \n",
       "105         -0.502042         -0.501060       -0.501676       0.000438   \n",
       "106         -0.502042         -0.501060       -0.501676       0.000438   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                69           -0.420502           -0.409594   \n",
       "1                64           -0.352692           -0.354747   \n",
       "2               106           -0.676007           -0.635802   \n",
       "3               104           -0.636046           -0.601932   \n",
       "4                69           -0.420502           -0.409594   \n",
       "..              ...                 ...                 ...   \n",
       "102              80           -0.499141           -0.499812   \n",
       "103              80           -0.499141           -0.499812   \n",
       "104              80           -0.499141           -0.499812   \n",
       "105              80           -0.499141           -0.499812   \n",
       "106              80           -0.499141           -0.499812   \n",
       "\n",
       "     split2_train_score  mean_train_score  std_train_score  \n",
       "0             -0.391547         -0.407215         0.011940  \n",
       "1             -0.329169         -0.345536         0.011604  \n",
       "2             -0.654674         -0.655494         0.016424  \n",
       "3             -0.619388         -0.619122         0.013928  \n",
       "4             -0.391547         -0.407215         0.011940  \n",
       "..                  ...               ...              ...  \n",
       "102           -0.499391         -0.499448         0.000277  \n",
       "103           -0.499391         -0.499448         0.000277  \n",
       "104           -0.499391         -0.499448         0.000277  \n",
       "105           -0.499391         -0.499448         0.000277  \n",
       "106           -0.499391         -0.499448         0.000277  \n",
       "\n",
       "[107 rows x 26 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.sort_values(by='rank_test_score', inplace=True)\n",
    "res.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_est</th>\n",
       "      <th>param_est__copy_X</th>\n",
       "      <th>param_est__fit_intercept</th>\n",
       "      <th>param_est__positive</th>\n",
       "      <th>param_est__alpha</th>\n",
       "      <th>param_est__early_stopping</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>SGDRegressor(alpha=0.001, early_stopping=True,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.337899</td>\n",
       "      <td>-0.392025</td>\n",
       "      <td>-0.357491</td>\n",
       "      <td>0.024493</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.353714</td>\n",
       "      <td>-0.355147</td>\n",
       "      <td>-0.329395</td>\n",
       "      <td>-0.346085</td>\n",
       "      <td>0.011816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025344</td>\n",
       "      <td>0.029307</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>SGDRegressor(alpha=0.001, early_stopping=True,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.337899</td>\n",
       "      <td>-0.392025</td>\n",
       "      <td>-0.357491</td>\n",
       "      <td>0.024493</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.353714</td>\n",
       "      <td>-0.355147</td>\n",
       "      <td>-0.329395</td>\n",
       "      <td>-0.346085</td>\n",
       "      <td>0.011816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006671</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>SGDRegressor(alpha=0.001, early_stopping=True,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.337899</td>\n",
       "      <td>-0.392025</td>\n",
       "      <td>-0.357491</td>\n",
       "      <td>0.024493</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.353714</td>\n",
       "      <td>-0.355147</td>\n",
       "      <td>-0.329395</td>\n",
       "      <td>-0.346085</td>\n",
       "      <td>0.011816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005198</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>SGDRegressor(alpha=0.001, early_stopping=True,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.337899</td>\n",
       "      <td>-0.391988</td>\n",
       "      <td>-0.357498</td>\n",
       "      <td>0.024464</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.353693</td>\n",
       "      <td>-0.355145</td>\n",
       "      <td>-0.329398</td>\n",
       "      <td>-0.346079</td>\n",
       "      <td>0.011810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004993</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>SGDRegressor(alpha=0.001, early_stopping=True,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.337899</td>\n",
       "      <td>-0.391988</td>\n",
       "      <td>-0.357498</td>\n",
       "      <td>0.024464</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.353693</td>\n",
       "      <td>-0.355145</td>\n",
       "      <td>-0.329398</td>\n",
       "      <td>-0.346079</td>\n",
       "      <td>0.011810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>ElasticNet()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.502042</td>\n",
       "      <td>-0.501060</td>\n",
       "      <td>-0.501676</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>80</td>\n",
       "      <td>-0.499141</td>\n",
       "      <td>-0.499812</td>\n",
       "      <td>-0.499391</td>\n",
       "      <td>-0.499448</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.041822</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.630327</td>\n",
       "      <td>-0.633520</td>\n",
       "      <td>-0.626791</td>\n",
       "      <td>0.007375</td>\n",
       "      <td>104</td>\n",
       "      <td>-0.636046</td>\n",
       "      <td>-0.601932</td>\n",
       "      <td>-0.619388</td>\n",
       "      <td>-0.619122</td>\n",
       "      <td>0.013928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.630327</td>\n",
       "      <td>-0.633520</td>\n",
       "      <td>-0.626791</td>\n",
       "      <td>0.007375</td>\n",
       "      <td>104</td>\n",
       "      <td>-0.636046</td>\n",
       "      <td>-0.601932</td>\n",
       "      <td>-0.619388</td>\n",
       "      <td>-0.619122</td>\n",
       "      <td>0.013928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669386</td>\n",
       "      <td>-0.676608</td>\n",
       "      <td>-0.659517</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>106</td>\n",
       "      <td>-0.676007</td>\n",
       "      <td>-0.635802</td>\n",
       "      <td>-0.654674</td>\n",
       "      <td>-0.655494</td>\n",
       "      <td>0.016424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669386</td>\n",
       "      <td>-0.676608</td>\n",
       "      <td>-0.659517</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>106</td>\n",
       "      <td>-0.676007</td>\n",
       "      <td>-0.635802</td>\n",
       "      <td>-0.654674</td>\n",
       "      <td>-0.655494</td>\n",
       "      <td>0.016424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.005747      0.000215         0.000849        0.000093   \n",
       "1         0.025344      0.029307         0.000666        0.000140   \n",
       "2         0.006671      0.001625         0.000854        0.000037   \n",
       "3         0.005198      0.001107         0.000760        0.000125   \n",
       "4         0.004993      0.000223         0.000818        0.000156   \n",
       "..             ...           ...              ...             ...   \n",
       "102       0.002472      0.000012         0.000944        0.000028   \n",
       "103       0.041822      0.002362         0.000849        0.000132   \n",
       "104       0.002078      0.000304         0.000832        0.000100   \n",
       "105       0.002279      0.000241         0.000944        0.000074   \n",
       "106       0.002396      0.000734         0.000928        0.000123   \n",
       "\n",
       "                                             param_est param_est__copy_X  \\\n",
       "0    SGDRegressor(alpha=0.001, early_stopping=True,...               NaN   \n",
       "1    SGDRegressor(alpha=0.001, early_stopping=True,...               NaN   \n",
       "2    SGDRegressor(alpha=0.001, early_stopping=True,...               NaN   \n",
       "3    SGDRegressor(alpha=0.001, early_stopping=True,...               NaN   \n",
       "4    SGDRegressor(alpha=0.001, early_stopping=True,...               NaN   \n",
       "..                                                 ...               ...   \n",
       "102                                       ElasticNet()               NaN   \n",
       "103                                 LinearRegression()              True   \n",
       "104                                 LinearRegression()             False   \n",
       "105                                 LinearRegression()              True   \n",
       "106                                 LinearRegression()             False   \n",
       "\n",
       "    param_est__fit_intercept param_est__positive param_est__alpha  \\\n",
       "0                        NaN                 NaN            0.001   \n",
       "1                        NaN                 NaN            0.001   \n",
       "2                        NaN                 NaN            0.001   \n",
       "3                        NaN                 NaN            0.001   \n",
       "4                        NaN                 NaN            0.001   \n",
       "..                       ...                 ...              ...   \n",
       "102                      NaN                 NaN              0.5   \n",
       "103                    False               False              NaN   \n",
       "104                    False               False              NaN   \n",
       "105                    False                True              NaN   \n",
       "106                    False                True              NaN   \n",
       "\n",
       "    param_est__early_stopping  ... split1_test_score split2_test_score  \\\n",
       "0                        True  ...         -0.337899         -0.392025   \n",
       "1                        True  ...         -0.337899         -0.392025   \n",
       "2                        True  ...         -0.337899         -0.392025   \n",
       "3                        True  ...         -0.337899         -0.391988   \n",
       "4                        True  ...         -0.337899         -0.391988   \n",
       "..                        ...  ...               ...               ...   \n",
       "102                       NaN  ...         -0.502042         -0.501060   \n",
       "103                       NaN  ...         -0.630327         -0.633520   \n",
       "104                       NaN  ...         -0.630327         -0.633520   \n",
       "105                       NaN  ...         -0.669386         -0.676608   \n",
       "106                       NaN  ...         -0.669386         -0.676608   \n",
       "\n",
       "    mean_test_score std_test_score rank_test_score  split0_train_score  \\\n",
       "0         -0.357491       0.024493               1           -0.353714   \n",
       "1         -0.357491       0.024493               1           -0.353714   \n",
       "2         -0.357491       0.024493               1           -0.353714   \n",
       "3         -0.357498       0.024464               4           -0.353693   \n",
       "4         -0.357498       0.024464               4           -0.353693   \n",
       "..              ...            ...             ...                 ...   \n",
       "102       -0.501676       0.000438              80           -0.499141   \n",
       "103       -0.626791       0.007375             104           -0.636046   \n",
       "104       -0.626791       0.007375             104           -0.636046   \n",
       "105       -0.659517       0.019291             106           -0.676007   \n",
       "106       -0.659517       0.019291             106           -0.676007   \n",
       "\n",
       "     split1_train_score  split2_train_score  mean_train_score  std_train_score  \n",
       "0             -0.355147           -0.329395         -0.346085         0.011816  \n",
       "1             -0.355147           -0.329395         -0.346085         0.011816  \n",
       "2             -0.355147           -0.329395         -0.346085         0.011816  \n",
       "3             -0.355145           -0.329398         -0.346079         0.011810  \n",
       "4             -0.355145           -0.329398         -0.346079         0.011810  \n",
       "..                  ...                 ...               ...              ...  \n",
       "102           -0.499812           -0.499391         -0.499448         0.000277  \n",
       "103           -0.601932           -0.619388         -0.619122         0.013928  \n",
       "104           -0.601932           -0.619388         -0.619122         0.013928  \n",
       "105           -0.635802           -0.654674         -0.655494         0.016424  \n",
       "106           -0.635802           -0.654674         -0.655494         0.016424  \n",
       "\n",
       "[107 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['model'] = res['param_est'].astype(str).str.split('(',1,True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_of_each = res.groupby('model')['rank_test_score'].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_est</th>\n",
       "      <th>param_est__copy_X</th>\n",
       "      <th>param_est__fit_intercept</th>\n",
       "      <th>param_est__positive</th>\n",
       "      <th>param_est__alpha</th>\n",
       "      <th>param_est__early_stopping</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>ElasticNet()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.397702</td>\n",
       "      <td>-0.383052</td>\n",
       "      <td>0.010605</td>\n",
       "      <td>66</td>\n",
       "      <td>-0.380034</td>\n",
       "      <td>-0.384490</td>\n",
       "      <td>-0.361602</td>\n",
       "      <td>-0.375375</td>\n",
       "      <td>0.009907</td>\n",
       "      <td>ElasticNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>Lasso()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.501060</td>\n",
       "      <td>-0.501676</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>80</td>\n",
       "      <td>-0.499141</td>\n",
       "      <td>-0.499812</td>\n",
       "      <td>-0.499391</td>\n",
       "      <td>-0.499448</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>Lasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.050557</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.391365</td>\n",
       "      <td>-0.359093</td>\n",
       "      <td>0.023111</td>\n",
       "      <td>64</td>\n",
       "      <td>-0.352692</td>\n",
       "      <td>-0.354747</td>\n",
       "      <td>-0.329169</td>\n",
       "      <td>-0.345536</td>\n",
       "      <td>0.011604</td>\n",
       "      <td>LinearRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>Ridge()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.391244</td>\n",
       "      <td>-0.359050</td>\n",
       "      <td>0.023055</td>\n",
       "      <td>55</td>\n",
       "      <td>-0.352692</td>\n",
       "      <td>-0.354747</td>\n",
       "      <td>-0.329169</td>\n",
       "      <td>-0.345536</td>\n",
       "      <td>0.011604</td>\n",
       "      <td>Ridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>SGDRegressor(alpha=0.001, early_stopping=True,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.392025</td>\n",
       "      <td>-0.357491</td>\n",
       "      <td>0.024493</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.353714</td>\n",
       "      <td>-0.355147</td>\n",
       "      <td>-0.329395</td>\n",
       "      <td>-0.346085</td>\n",
       "      <td>0.011816</td>\n",
       "      <td>SGDRegressor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "65       0.002710      0.000264         0.000909        0.000013   \n",
       "93       0.002485      0.000049         0.000994        0.000114   \n",
       "63       0.050557      0.008624         0.000947        0.000007   \n",
       "54       0.002292      0.000129         0.000912        0.000033   \n",
       "0        0.005747      0.000215         0.000849        0.000093   \n",
       "\n",
       "                                            param_est param_est__copy_X  \\\n",
       "65                                       ElasticNet()               NaN   \n",
       "93                                            Lasso()               NaN   \n",
       "63                                 LinearRegression()              True   \n",
       "54                                            Ridge()               NaN   \n",
       "0   SGDRegressor(alpha=0.001, early_stopping=True,...               NaN   \n",
       "\n",
       "   param_est__fit_intercept param_est__positive param_est__alpha  \\\n",
       "65                      NaN                 NaN              0.5   \n",
       "93                      NaN                 NaN              1.5   \n",
       "63                     True               False              NaN   \n",
       "54                      NaN                 NaN              1.5   \n",
       "0                       NaN                 NaN            0.001   \n",
       "\n",
       "   param_est__early_stopping  ... split2_test_score mean_test_score  \\\n",
       "65                       NaN  ...         -0.397702       -0.383052   \n",
       "93                       NaN  ...         -0.501060       -0.501676   \n",
       "63                       NaN  ...         -0.391365       -0.359093   \n",
       "54                       NaN  ...         -0.391244       -0.359050   \n",
       "0                       True  ...         -0.392025       -0.357491   \n",
       "\n",
       "   std_test_score rank_test_score split0_train_score  split1_train_score  \\\n",
       "65       0.010605              66          -0.380034           -0.384490   \n",
       "93       0.000438              80          -0.499141           -0.499812   \n",
       "63       0.023111              64          -0.352692           -0.354747   \n",
       "54       0.023055              55          -0.352692           -0.354747   \n",
       "0        0.024493               1          -0.353714           -0.355147   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score             model  \n",
       "65           -0.361602         -0.375375         0.009907        ElasticNet  \n",
       "93           -0.499391         -0.499448         0.000277             Lasso  \n",
       "63           -0.329169         -0.345536         0.011604  LinearRegression  \n",
       "54           -0.329169         -0.345536         0.011604             Ridge  \n",
       "0            -0.329395         -0.346085         0.011816      SGDRegressor  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.iloc[best_of_each]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implemente o algoritmo RegressÃ£o LogÃ­stica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logistic_regression import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression as LogisticRegressionSkl\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treine e avalie (de acordo com a mÃ©trica F1-Score), usando a RegressÃ£o LogÃ­stica implementada por vocÃª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = my_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4539007092198582"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare o resultado de sua implementaÃ§Ã£o com a implementaÃ§Ã£o LogisticRegression do scikit learn em um grid search, que varia para a implementaÃ§Ã£o do scikit learn, os seguintes hiper-parÃ¢metros: penalty, C, solver, max_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_lr = LogisticRegressionSkl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = skl_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8508771929824561"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {\n",
    "  \"penalty\": ['l2', 'none'], \n",
    "  \"C\": [0.5,1.0,1.5], \n",
    "  \"solver\": ['newton-cg', 'lbfgs', 'sag'], \n",
    "  \"max_iter\": [50,100,150],\n",
    "  \"random_state\": [42]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_lr = GridSearchCV(LogisticRegressionSkl(verbose=0), lr_params, cv=3, n_jobs=-1, return_train_score=True, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alcides/.local/opt/miniconda/envs/machine_learning/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [0.5, 1.0, 1.5], 'max_iter': [50, 100, 150],\n",
       "                         'penalty': ['l2', 'none'], 'random_state': [42],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'sag']},\n",
       "             return_train_score=True, scoring='f1')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.5,\n",
       " 'max_iter': 50,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': 42,\n",
       " 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8533333333333333"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = my_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4539007092198582"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 ('machine_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ed5d1d1dfe9b2261c7a773d4a02e4cd4211327f910f2d56bd92bd353db7856e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
