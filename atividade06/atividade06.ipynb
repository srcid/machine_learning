{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>M</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>0.1931</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8913</th>\n",
       "      <td>B</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8915</th>\n",
       "      <td>B</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9047</th>\n",
       "      <td>B</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>0.1735</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85715</th>\n",
       "      <td>M</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "id                                                                      \n",
       "8670          M        15.46         19.48          101.70      748.9   \n",
       "8913          B        12.89         13.12           81.89      515.9   \n",
       "8915          B        14.96         19.10           97.03      687.3   \n",
       "9047          B        12.94         16.17           83.18      507.6   \n",
       "85715         M        13.17         18.66           85.98      534.6   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "id                                                                              \n",
       "8670           0.10920           0.12230         0.14660              0.08087   \n",
       "8913           0.06955           0.03729         0.02260              0.01171   \n",
       "8915           0.08992           0.09823         0.05940              0.04819   \n",
       "9047           0.09879           0.08836         0.03296              0.02390   \n",
       "85715          0.11580           0.12310         0.12260              0.07340   \n",
       "\n",
       "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "id                    ...                                                 \n",
       "8670          0.1931  ...         19.26          26.00           124.90   \n",
       "8913          0.1337  ...         13.62          15.54            87.40   \n",
       "8915          0.1879  ...         16.25          26.19           109.10   \n",
       "9047          0.1735  ...         13.86          23.02            89.69   \n",
       "85715         0.2128  ...         15.67          27.95           102.80   \n",
       "\n",
       "       area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "id                                                                        \n",
       "8670       1156.0           0.15460             0.2394           0.3791   \n",
       "8913        577.0           0.09616             0.1147           0.1186   \n",
       "8915        809.8           0.13130             0.3030           0.1804   \n",
       "9047        580.9           0.11720             0.1958           0.1810   \n",
       "85715       759.4           0.17860             0.4166           0.5006   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "id                                                                    \n",
       "8670                0.15140          0.2837                  0.08019  \n",
       "8913                0.05366          0.2309                  0.06915  \n",
       "8915                0.14890          0.2962                  0.08472  \n",
       "9047                0.08388          0.3297                  0.07834  \n",
       "85715               0.20880          0.3900                  0.11790  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/breast_cancer_wisconsin.csv', index_col='id').sort_index()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperando _features_ ou x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>0.1931</td>\n",
       "      <td>0.05796</td>\n",
       "      <td>0.4743</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8913</th>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>0.1532</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8915</th>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.05852</td>\n",
       "      <td>0.2877</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9047</th>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>0.1735</td>\n",
       "      <td>0.06200</td>\n",
       "      <td>0.1458</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85715</th>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.06777</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "id                                                                \n",
       "8670          19.48          101.70      748.9          0.10920   \n",
       "8913          13.12           81.89      515.9          0.06955   \n",
       "8915          19.10           97.03      687.3          0.08992   \n",
       "9047          16.17           83.18      507.6          0.09879   \n",
       "85715         18.66           85.98      534.6          0.11580   \n",
       "\n",
       "       compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "id                                                                            \n",
       "8670            0.12230         0.14660              0.08087         0.1931   \n",
       "8913            0.03729         0.02260              0.01171         0.1337   \n",
       "8915            0.09823         0.05940              0.04819         0.1879   \n",
       "9047            0.08836         0.03296              0.02390         0.1735   \n",
       "85715           0.12310         0.12260              0.07340         0.2128   \n",
       "\n",
       "       fractal_dimension_mean  radius_se  ...  radius_worst  texture_worst  \\\n",
       "id                                        ...                                \n",
       "8670                  0.05796     0.4743  ...         19.26          26.00   \n",
       "8913                  0.05581     0.1532  ...         13.62          15.54   \n",
       "8915                  0.05852     0.2877  ...         16.25          26.19   \n",
       "9047                  0.06200     0.1458  ...         13.86          23.02   \n",
       "85715                 0.06777     0.2871  ...         15.67          27.95   \n",
       "\n",
       "       perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "id                                                                        \n",
       "8670            124.90      1156.0           0.15460             0.2394   \n",
       "8913             87.40       577.0           0.09616             0.1147   \n",
       "8915            109.10       809.8           0.13130             0.3030   \n",
       "9047             89.69       580.9           0.11720             0.1958   \n",
       "85715           102.80       759.4           0.17860             0.4166   \n",
       "\n",
       "       concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "id                                                             \n",
       "8670            0.3791               0.15140          0.2837   \n",
       "8913            0.1186               0.05366          0.2309   \n",
       "8915            0.1804               0.14890          0.2962   \n",
       "9047            0.1810               0.08388          0.3297   \n",
       "85715           0.5006               0.20880          0.3900   \n",
       "\n",
       "       fractal_dimension_worst  \n",
       "id                              \n",
       "8670                   0.08019  \n",
       "8913                   0.06915  \n",
       "8915                   0.08472  \n",
       "9047                   0.07834  \n",
       "85715                  0.11790  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,2:]\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando _labels_ ou y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "8670     M\n",
       "8913     B\n",
       "8915     B\n",
       "9047     B\n",
       "85715    M\n",
       "Name: diagnosis, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['diagnosis']\n",
    "y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Divida o conjunto de dados entre Treino (80%) e Teste (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=80/100, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = {}\n",
    "\n",
    "modelos['DT']     = tree.DecisionTreeClassifier()\n",
    "modelos['SVM']    = svm.SVC()\n",
    "modelos['KNN']    = neighbors.KNeighborsClassifier()\n",
    "modelos['LogReg'] = linear_model.LogisticRegression(multi_class='multinomial',solver='newton-cg')\n",
    "modelos['NB']     = naive_bayes.GaussianNB()\n",
    "modelos['SGD']    = linear_model.SGDClassifier()\n",
    "modelos['RF']     = ensemble.RandomForestClassifier()\n",
    "modelos['GB']     = ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VALIDAÃ‡ÃƒO CRUZADA K-FOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Aplique uma validaÃ§Ã£o cruzada 5-Fold (ou seja: k-Fold, com k=5) usando diferentes algoritmos de classificaÃ§Ã£o e escolha o algoritmo que obtiver melhor acurÃ¡cia. Dica: usar cross_val_score do scikit-learn. Para entender melhor o 5-Fold Cross Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DT': 0.9076923076923077,\n",
       " 'SVM': 0.9142857142857144,\n",
       " 'KNN': 0.945054945054945,\n",
       " 'LogReg': 0.9516483516483516,\n",
       " 'NB': 0.9428571428571428,\n",
       " 'SGD': 0.8351648351648352,\n",
       " 'RF': 0.9626373626373625,\n",
       " 'GB': 0.956043956043956}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {}\n",
    "\n",
    "for k,m in modelos.items():\n",
    "  model = copy(m)\n",
    "  scores[k] = cross_val_score(model, X_train, y_train, cv=5, n_jobs=10).mean()\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RF'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_alg = max(scores, key=scores.get)\n",
    "best_alg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Gere (treine) um modelo de classificaÃ§Ã£o usando o melhor algoritmo obtido na questÃ£o 2 sobre todo o conjunto de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = modelos[best_alg]\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Calcule a acurÃ¡cia do modelo gerado na questÃ£o 3 sobre o conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escalonamento de _features_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Reexecute as questÃµes de 1 a 4 sÃ³ que usando os seguintes escalonamentos de caracterÃ­sticas (features): MinMaxScaler e StandardScaler. Dica: use cada um separadamente para obter uma acurÃ¡cia final para cada um deles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF 0.9035087719298246\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(scaler.fit_transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "for k,m in modelos.items():\n",
    "  model = copy(m)\n",
    "  scores[k] = cross_val_score(model, X_train, y_train, n_jobs=10).mean()\n",
    "\n",
    "best_alg = max(scores, key=scores.get)\n",
    "\n",
    "model = copy(modelos[best_alg])\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(best_alg, model.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandartScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(scaler.fit_transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "for k,m in modelos.items():\n",
    "  model = copy(m)\n",
    "  scores[k] = cross_val_score(model, X_train, y_train, n_jobs=10).mean()\n",
    "\n",
    "best_alg = max(scores, key=scores.get)\n",
    "\n",
    "model = copy(modelos[best_alg])\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(best_alg, model.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIPELINE\n",
    "\n",
    "6. RefaÃ§a a questÃ£o 5, sÃ³ que usando Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('transform', MinMaxScaler()),\n",
    "  ('estimator', copy(modelos['RF'])),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('transform', StandardScaler()),\n",
    "  ('estimator', copy(modelos['RF'])),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRID SEARCH COM VALIDAÃ‡ÃƒO CRUZADA\n",
    "\n",
    "### 7. Use um Grid Search com ValidaÃ§Ã£o Cruzada 5-Fold sobre o conjunto de treino e:\n",
    "\n",
    "a) obtenha os melhores hiper-parÃ¢metros do Gradient Boosting para os seguintes hiper-parÃ¢metros:\n",
    "\n",
    "learning_rate: 0.1, 0.05, 0.01, 0.005, 0.001  \n",
    "n_estimators: 10, 50, 100, 200, 400  \n",
    "max_depth: 3, 5, 7, 9  \n",
    "subsample: 0.5, 0.8, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=10,\n",
       "             param_grid=[{'learning_rate': [0.1, 0.05, 0.01, 0.005, 0.001],\n",
       "                          'max_depth': [3, 5, 7, 9],\n",
       "                          'n_estimators': [10, 50, 100, 200, 400],\n",
       "                          'subsample': [0.5, 0.8, 1.0]}])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{\n",
    "  'learning_rate': [0.1, 0.05, 0.01, 0.005, 0.001],\n",
    "  'n_estimators': [10, 50, 100, 200, 400],\n",
    "  'max_depth': [3, 5, 7, 9],\n",
    "  'subsample': [0.5, 0.8, 1.0]\n",
    "},]\n",
    "\n",
    "gb = copy(modelos['GB'])\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "  gb,\n",
    "  param_grid,\n",
    "  cv=5,\n",
    "  scoring='accuracy',\n",
    "  n_jobs=10\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(n_estimators=400, subsample=0.5)\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 400, 'subsample': 0.5}\n",
      "0.9758241758241757\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "grid_search.best_estimator_,\n",
    "grid_search.best_params_,\n",
    "grid_search.best_score_,\n",
    "sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Gere (treine) um modelo de classificaÃ§Ã£o usando os melhores hiper-parÃ¢metros obtidos no item (a) sobre todo o conjunto de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gb = ensemble.GradientBoostingClassifier(n_estimators=400, subsample=0.5, learning_rate=0.1, max_depth=3)\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred = gb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Calcule a acurÃ¡cia do modelo gerado no item (b) sobre o conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOMIZED SEARCH COM VALIDAÃ‡ÃƒO CRUZADA\n",
    "\n",
    "8. RefaÃ§a a QuestÃ£o 7, sÃ³ que usando o Randomized Search com ValidaÃ§Ã£o Cruzada ao invÃ©s do Grid Search com ValidaÃ§Ã£o Cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=10,\n",
       "                   param_distributions=[{'learning_rate': [0.1, 0.05, 0.01,\n",
       "                                                           0.005, 0.001],\n",
       "                                         'max_depth': [3, 5, 7, 9],\n",
       "                                         'n_estimators': [10, 50, 100, 200,\n",
       "                                                          400],\n",
       "                                         'subsample': [0.5, 0.8, 1.0]}],\n",
       "                   scoring='accuracy')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = [{\n",
    "  'learning_rate': [0.1, 0.05, 0.01, 0.005, 0.001],\n",
    "  'n_estimators': [10, 50, 100, 200, 400],\n",
    "  'max_depth': [3, 5, 7, 9],\n",
    "  'subsample': [0.5, 0.8, 1.0]\n",
    "},]\n",
    "\n",
    "gb = copy(modelos['GB'])\n",
    "\n",
    "rd_search = RandomizedSearchCV(\n",
    "  gb,\n",
    "  param_grid,\n",
    "  cv=5,\n",
    "  scoring='accuracy',\n",
    "  n_jobs=10\n",
    ")\n",
    "\n",
    "rd_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(learning_rate=0.05, max_depth=7, n_estimators=200,\n",
      "                           subsample=0.5)\n",
      "{'subsample': 0.5, 'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.05}\n",
      "0.9648351648351647\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "rd_search.best_estimator_,\n",
    "rd_search.best_params_,\n",
    "rd_search.best_score_,\n",
    "sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = ensemble.GradientBoostingClassifier(n_estimators=200, subsample=0.5, learning_rate=0.05, max_depth=7)\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956140350877193"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ed5d1d1dfe9b2261c7a773d4a02e4cd4211327f910f2d56bd92bd353db7856e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('machine_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
